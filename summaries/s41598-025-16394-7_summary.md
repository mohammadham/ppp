# Deep learning steganography for big data security using squeeze and excitation with inception architectures

## Article Metadata
- **Authors**: Bini M. Issac, S. N. Kumar, Sherin Zafar, Kashish Ara Shakil, Mudasar Ahmad Wani
- **Affiliations**: Amal Jyothi College of Engineering (India), Jamia Hamdard (India), Princess Nourah Bint Abdulrahman University (Saudi Arabia), Prince Sultan University (Saudi Arabia)
- **Journal**: Scientific Reports (Nature)
- **Year**: 2025
- **DOI**: s41598-025-16394-7

---

## Abstract Summary

With the exponential growth of big data in domains such as telemedicine and digital forensics, secure transmission of sensitive medical information has become critical. Conventional steganographic methods fail to maintain diagnostic integrity or exhibit robustness against noise and transformations. This study proposes a **novel deep learning-based steganographic framework** combining:

- **Squeeze-and-Excitation (SE) blocks**
- **Inception modules**
- **Residual connections**

The encoder integrates dilated convolutions and SE attention to embed secret medical images within natural cover images, while the decoder employs residual and multi-scale Inception-based feature extraction for accurate reconstruction. Designed for deployment on **NVIDIA Jetson TX2**, the model ensures real-time, low-power operation suitable for edge healthcare applications.

**Key Results**:
- **PSNR**: 39.02 (MRI), 38.75 (OCT)
- **SSIM**: 0.9757
- **Processing time**: 25-35 ms per image
- **Throughput**: 25-30 images/second

---

## Keywords

Medical image security, Steganography, Squeeze-and-Excitation, Inception module, Deep learning, Jetson TX2, Telemedicine

---

## 1. Introduction & Motivation

### Background
- Rapid growth of telemedicine and big data technologies has transformed diagnostic workflows
- Multiple scans (MRI, CT, OCT) per patient result in high-resolution, large-scale datasets with sensitive medical information
- COVID-19 pandemic accelerated shift toward cloud-based platforms for transmitting medical images
- Critical challenges: **data confidentiality, integrity, and computational efficiency**

### Problems with Traditional Steganography

**Spatial Domain Methods (LSB, PVD)**:
- ❌ Limited resilience to noise, compression, and transformations
- ❌ Unsuitable for telehealth where images undergo varied transmission conditions
- ❌ Compromise balance between embedding capacity and image quality
- ❌ Unacceptable trade-off in diagnostic imaging where visual fidelity is non-negotiable

**Transform Domain Methods (DCT, DWT, DFT)**:
- ❌ Computationally intensive
- ❌ Poor suited for edge deployment
- ❌ Limiting practical application in low-power medical environments

### Proposed Solution

A **hybrid steganographic framework** integrating:
1. **Residual connections** - for deep feature retention and gradient flow
2. **Squeeze-and-Excitation (SE) attention** - channel-wise recalibration
3. **Inception modules** - multi-scale feature extraction
4. **Dilated convolutions** - expanded receptive field

**Optimized for**: Real-time deployment on NVIDIA Jetson TX2 (resource-constrained edge device)

---

## 2. Key Contributions

1. **Hybrid Encoder-Decoder Architecture**:
   - Integrates SE blocks, dilated convolutions, and Inception modules
   - Enhances embedding robustness and reconstruction fidelity

2. **Advanced Decoder Network**:
   - Employs residual connections and multi-scale feature extraction
   - Recovers secret images with minimal distortion under challenging conditions (noise, compression)

3. **Edge Deployment Optimization**:
   - Optimized for NVIDIA Jetson TX2 platform
   - Enables real-time, low-power operation (7.5-15W) for telemedicine/teleradiology

4. **Superior Performance**:
   - Extensive experiments on Brain MRI and OCT glaucoma datasets
   - Superior PSNR, SSIM, NCC, LMSE metrics

5. **Outperforms Traditional Methods**:
   - Better imperceptibility, payload capacity, and robustness to perturbations
   - Compared to LSB, PVD, DCT, DWT, and recent deep learning methods

---

## 3. Literature Review

### Classical Spatial Domain Methods

**LSB (Least Significant Bit)**:
- ✅ Simple, low computational overhead, minimal visual distortion
- ❌ Vulnerable to statistical attacks, noise, format conversions, compression artifacts

**LSB Enhancements**:
- LSB matching, adaptive embedding based on image intensity/edge features
- Multi-plane LSB expansion (compromises imperceptibility)

**PVD (Pixel Value Differencing)**:
- ✅ Improved imperceptibility by aligning with human visual sensitivity
- ❌ Vulnerable to histogram-based steganalysis, lacks randomness

**Security-Enhanced PVD**:
- iRMDR (improved Rightmost Digit Replacement)
- PBPVD (Parity-Bit PVD)
- Pseudo-random block selection

**Hybrid LSB+PVD**:
- ⚠️ Incremental improvements but still fall short of robustness required for medical data transmission

---

### Transform Domain Methods

**DCT (Discrete Cosine Transform)**:
- ✅ Greater resilience against noise and signal processing
- ✅ Suitable for JPEG-compressed images
- ❌ Prone to blocking artifacts, limited payload capacity

**DWT (Discrete Wavelet Transform)**:
- ✅ Multi-resolution sub-bands, suitable for high-resolution modalities (CT, MRI)
- ❌ Susceptible to geometric distortions, perceptual artifacts in sensitive regions

**DFT (Discrete Fourier Transform)**:
- ✅ Phase modification imperceptible to human eye
- ❌ Global nature means minor frequency changes have broad spatial impact
- ❌ Less effective for localized/structure-preserving medical applications

---

### Deep Learning-Based Methods

**Early DL Steganography**:
- Baluja (2017): Pioneered DL-based image steganography, complete image hidden within another
- ❌ Poor visual fidelity of stego images

**U-Net Architecture**:
- Duan et al.: Extracted and integrated hierarchical features, improved visual quality
- Yu et al.: Introduced attention masks to identify optimal embedding regions

**Advanced DL Methods**:
- **ISN (Invertible Steganography Network)**: Parameter-sharing mechanisms for efficient embedding
- **Wavelet Loss Integration**: Guided embedding into high-frequency regions, preserved structural details
- **Channel Attention**: Highlighted salient features
- **Spatial-Channel Joint Attention**: Minimized distortion within invertible framework

**Limitations of Existing DL Methods**:
- ❌ Fixed-kernel convolutional attention limits receptive field and adaptability
- ❌ Struggle with extracting fine-grained secret features
- ❌ Distortions in reconstructed images

**Proposed SE Block Solution**:
- ✅ Dynamically recalibrate channel-wise feature activations
- ✅ Model focuses on most relevant information during encoding/decoding
- ✅ Improves robustness while preserving quality of stego and extracted medical images

---

## 4. Methodology

### Overall Architecture

**Two Core Modules**:
1. **Encoder**: Embeds secret medical images into natural cover images
2. **Decoder**: Reconstructs hidden images with minimal perceptual distortion

**Key Components**:
- Deep convolutional operations
- Attention mechanisms (SE blocks)
- Multi-scale feature learning (Inception modules)
- Residual connections for gradient flow

---

### 4.1 Encoder Architecture

**Input Processing**:
- Cover image $I_c$ + Secret medical image $I_s$ (resized to same dimensions)
- Concatenation: $I_{concat} = Concat(I_c, I_s)$ (Eq. 1)

**Feature Extraction**:
- Sequence of 3×3 convolutional layers (64 filters)
- ReLU activation, batch normalization, residual skip connections

**Squeeze-and-Excitation (SE) Attention**:

Given feature map $F \in \mathbb{R}^{H \times W \times C}$:

1. **Squeeze** (Global Average Pooling):
   $$z_c = \frac{1}{H \times W} \sum_{i=1}^{H} \sum_{j=1}^{W} F_{i,j,c}$$
   (Eq. 2)

2. **Excitation** (Two FC layers with non-linear activation):
   $$s = \sigma(W_2 \cdot \delta(W_1 \cdot z))$$
   (Eq. 3)

3. **Scaling** (Rescale feature map):
   $$\hat{F}_{i,j,c} = s_c \cdot F_{i,j,c}$$
   (Eq. 4)

**Purpose**: Enhances model's ability to focus on semantically meaningful features relevant for embedding

**Dilated Convolutions**:
- Capture multi-scale spatial information without increasing computational cost
- Dilation rates $r = \{2, 4, 8\}$
- Increase receptive field, encode contextual features at varying levels:
  $$F_{dilated}^{(r)} = Conv_{3 \times 3}^{(dilation=r)}(F)$$
  (Eq. 5)
- Smaller rates: capture texture and edges
- Larger rates: encode global patterns

**Skip Connections & Feature Aggregation**:
- Residual skip connections between intermediate feature maps
- Aligned using 1×1 convolutions:
  $$F_{agg} = Conv_{1 \times 1}(F_1) + Conv_{1 \times 1}(F_2)$$
  (Eq. 6)

**Encoded Output**:
- Final convolutional layer + sigmoid activation:
  $$I_{encoded} = \sigma(Conv_{3 \times 3}(F_{agg}))$$
  (Eq. 7)
- Stego image retains same shape as cover image
- Visually resembles cover while imperceptibly containing embedded medical content

---

### 4.2 Decoder Architecture

**Purpose**: Reconstructs hidden medical image from stego image while preserving structural and visual integrity

**Initial Feature Extraction**:
$$F_1 = ReLU(W_1 * I_{stego} + B_1)$$
(Eq. 8)
- 3×3 kernel, 64 filters
- Captures low-level spatial patterns

**Residual Feature Mapping**:
- Two convolutional layers with ReLU + shortcut connection
- Enables identity mappings, preserves fine-grained details:
  $$F_{r1} = ReLU(W_{r1} * F_{in} + B_{r1})$$
  (Eq. 9)
  $$F_{r2} = W_{r2} * F_{r1} + B_{r2}$$
  (Eq. 10)
- If dimensions differ, 1×1 convolution aligns channels:
  $$F_{out} = F_{r2} + Conv_{1 \times 1}(F_{in})$$
  (Eq. 11)

**Multi-Scale Decoding via Inception Modules**:
- Parallel convolutional filters (1×1, 3×3, 5×5)
- Captures both fine and coarse details:
  $$F_{1 \times 1} = ReLU(W_{1 \times 1} * F + B_{1 \times 1})$$
  (Eq. 12)
  $$F_{3 \times 3} = ReLU(W_{3 \times 3} * F + B_{3 \times 3})$$
  (Eq. 13)
  $$F_{5 \times 5} = ReLU(W_{5 \times 5} * F + B_{5 \times 5})$$
  (Eq. 14)
- Concatenation:
  $$F_{concat} = [F_{1 \times 1}, F_{3 \times 3}, F_{5 \times 5}]$$
  (Eq. 15)

**Final Reconstruction**:
- 3×3 convolutional layer + sigmoid activation:
  $$I_{decoded} = \sigma(W_f * F_{concat} + B_f)$$
  (Eq. 16)
- Ensures pixel values in normalized range [0, 1]

---

## 5. Experiments and Results

### Hardware & Software Configuration

**Platform**: NVIDIA Jetson TX2
- 256-core Pascal GPU
- Quad-core ARM CPU
- 8 GB LPDDR4 RAM
- Power-efficient embedded system

**Software**: Python 3.8, PyTorch, CUDA, cuDNN, PyTorch Lightning, TensorBoard

---

### Datasets

1. **Cover Images**: 600 natural flower images (Kaggle)
2. **Secret Images (Medical)**:
   - 600 MRI brain scans (tumor detection)
   - 600 OCT eye images (glaucoma detection)

**Pre-processing**:
- Standardized resolution: 256×256×3
- 80:20 train-test split

**Training**:
- 200 epochs
- Batch size: 8
- Optimizer: Adam (learning rate = 0.0001)

---

### Quantitative Evaluation Metrics

#### 1. Peak Signal-to-Noise Ratio (PSNR)
$$PSNR = 10 \cdot \log_{10} \left( \frac{MAX^2}{MSE} \right)$$
(Eq. 17)

**Results**:
- **MRI Brain**: Average PSNR = **39.02 dB**
- **OCT Glaucoma**: Average PSNR = **38.75 dB**
- Median: ~39 dB, range: 38-40 dB
- One upper outlier: >42 dB (enhanced reconstruction)

---

#### 2. Mean Squared Error (MSE)
$$MSE = \frac{1}{M \times N} \sum_{i=1}^{M} \sum_{j=1}^{N} (I_s(i, j) - I_{decoded}(i, j))^2$$
(Eq. 18)

**Results**:
- Median: ~9
- Range: 7-12
- No extreme outliers (stable model)

---

#### 3. Structural Content (SC)
$$SC = \frac{\sum I_s(i, j)^2}{\sum I_{decoded}(i, j)^2}$$
(Eq. 19)

**Results**:
- Centered around **1.05**
- Excellent preservation of structural content (critical for medical imaging)

---

#### 4. Normalized Cross-Correlation (NCC)
$$NCC = \frac{\sum I_s(i, j) \cdot I_{decoded}(i, j)}{\sum I_s(i, j)^2}$$
(Eq. 20)

**Results**:
- Predominantly above **0.96**
- Median: ~0.97
- One upper outlier: 1.0
- Confirms excellent reconstruction fidelity

---

#### 5. Maximum Difference (MD)
$$MD = max |I_s(i, j) - I_{decoded}(i, j)|$$
(Eq. 21)

**Results**:
- Range: 25-35
- Median: ~30
- Few samples with higher deviation (localized image complexity)

---

#### 6. Laplacian Mean Squared Error (LMSE)
$$LMSE = \frac{\sum [\nabla^2 I_s(i, j) - \nabla^2 I_{decoded}(i, j)]^2}{\sum [\nabla^2 I_s(i, j)]^2}$$
(Eq. 22)

**Results**:
- Range: 0.09-0.15
- Median: ~0.11
- Low LMSE (<0.1) signifies excellent structural preservation

---

#### 7. Normalized Absolute Error (NAE)
$$NAE = \frac{\sum |I_s(i, j) - I_{decoded}(i, j)|}{\sum |I_s(i, j)|}$$
(Eq. 23)

**Results**:
- Median: ~0.06
- Low variability
- NAE <0.05 considered excellent (close to this threshold)

---

#### 8. Structural Similarity Index Measure (SSIM)
$$SSIM(I_s, I_d) = \frac{(2\mu_s\mu_{decoded} + C_1)(2\sigma_{s,decoded} + C_2)}{(\mu_s^2 + \mu_{decoded}^2 + C_1)(\sigma_s^2 + \sigma_{decoded}^2 + C_2)}$$
(Eq. 24)

**Results**:
- Median: **~0.98**
- Minimum: >0.95
- Confirms minimal perceptual distortion and excellent structural consistency

---

## 6. Robustness Analysis Under Perturbations

**Four Perturbation Types Tested**:

| Perturbation Type | PSNR (dB) | SSIM | Assessment |
|-------------------|-----------|------|------------|
| **JPEG Compression (Q=75)** | **39.02** | **0.975** | ✅ Highest - minimal degradation, highly resilient to lossy compression |
| **Gaussian Noise (σ=0.01)** | 37.55 | 0.963 | ✅ Moderate impact - slight pixel perturbations but preserved structural integrity |
| **Cropping + Resizing** | 36.10 | 0.950 | ⚠️ Noticeable degradation - interpolation and border information loss |
| **Salt & Pepper Noise** | 34.70 | 0.931 | ⚠️ Greatest challenge - high-intensity localized noise |

**Conclusion**:
- ✅ Robust under realistic distortions (compression, Gaussian noise)
- ⚠️ Slight performance degradation under spatial transformations and impulsive noise
- Future work: Noise-aware training schemes

---

## 7. Ablation Study

**Purpose**: Evaluate individual contributions of key architectural components

| Model | Modification | PSNR (dB) | SSIM | Analysis |
|-------|--------------|-----------|------|----------|
| **Proposed (Full)** | All components | **39.02** | **0.975** | Baseline performance |
| **Model A** | ❌ Residual connections removed | 34.12 | 0.915 | Critical role in feature propagation and gradient flow |
| **Model B** | ❌ SE blocks excluded | 35.05 | 0.927 | Channel-wise attention essential for recalibrating features |
| **Model C** | ❌ Dilated → Standard convolutions | 33.80 | 0.910 | Dilated convolutions expand receptive field effectively |
| **Model D** | ❌ Inception modules removed | 34.50 | 0.918 | Multi-scale feature extraction crucial for adaptability |
| **Model E** | ❌ SE blocks + Dilated convolutions | 33.30 | 0.905 | Complementary roles in balancing local emphasis & global context |
| **Model F** | ❌ All attention mechanisms | 32.90 | 0.895 | Attention enhances discriminative features |
| **Model G** | ❌ Residual + Attention mechanisms | 32.20 | 0.880 | **Worst performance** - synergistic importance confirmed |

**Key Findings**:
1. **Residual connections** most critical (5 dB drop when removed)
2. **SE blocks** provide 4 dB improvement over baseline without them
3. **Dilated convolutions** essential for spatial feature extraction (5 dB contribution)
4. **Inception modules** add 4.5 dB improvement
5. **Combined removal** leads to catastrophic 7 dB performance drop

---

## 8. Hardware Implementation on Jetson TX2

### Deployment Specifications

| Category | Details | Feasibility |
|----------|---------|-------------|
| **Hardware** | 256-core Pascal GPU, 6-core ARM CPU, 8 GB RAM | Compact, powerful edge AI hardware for medical use |
| **Power Consumption** | 7.5-15 W (moderate-to-high load) | Low enough for mobile clinics, battery-powered tools |
| **Energy Efficiency** | ~0.5 W/image | Energy-efficient for real-time steganography |
| **Model Size** | 25-30 MB | Lightweight for TX2's storage |
| **Disk Usage** | ~3.0 GB (model + dataset + dependencies) | Easily accommodated |
| **RAM Usage** | 1.8-2.2 GB during inference | Fits comfortably within 8 GB |
| **Processing Time** | **25-35 ms per image** | ✅ Real-time achievable |
| **Throughput** | **25-30 images/sec** | ✅ Suitable for continuous/batch transmission |
| **Operating Temperature** | 0-50°C | Suitable for mobile labs, rural health units |
| **Deployment Feasibility** | Plug-and-play | High - no external dependencies beyond CUDA stack |

**Architecture Benefits**:
- ✅ Residual connections facilitate deep feature propagation
- ✅ SE blocks enhance attention-based refinement
- ✅ Inception modules enable multi-scale spatial feature extraction
- ✅ CUDA parallel processing accelerates convolutional operations, adaptive embedding, and decoding

---

## 9. Benchmarking with State-of-the-Art

### Comparison on Sample Images (Table 4)

**MRI Brain Dataset** (3 samples):

| Method | PSNR Range | SSIM Range | MSE Range |
|--------|------------|------------|-----------|
| HiDDeN | 36.85-37.25 dB | 0.96-0.97 | 5.91-6.40 |
| SteganoGAN | 35.96-36.56 dB | 0.96 | 6.75-7.62 |
| HCISNet | 37.65-38.99 dB | 0.97 | 3.91-5.42 |
| AVGGAN | 39.95-40.25 dB | 0.98 | 2.54-2.61 |
| **Proposed** | **40.30-41.96 dB** | **0.98-0.99** | **4.13-6.05** |

**OCT Glaucoma Dataset** (3 samples):

| Method | PSNR Range | SSIM Range | MSE Range |
|--------|------------|------------|-----------|
| HiDDeN | 36.86-38.45 dB | 0.96-0.97 | 4.27-6.34 |
| SteganoGAN | 36.22-37.23 dB | 0.95-0.96 | 5.79-7.54 |
| HCISNet | 37.44-38.44 dB | 0.97 | 4.28-5.17 |
| AVGGAN | 38.13-38.95 dB | 0.98 | 3.39-4.26 |
| **Proposed** | **38.51-39.71 dB** | **0.96-0.98** | **6.94-9.14** |

---

### Average Performance over 25 Test Images (Table 5)

| Method | SSIM (MRI) | PSNR (MRI) | SSIM (OCT) | PSNR (OCT) |
|--------|------------|------------|------------|------------|
| HiDDeN | 0.96 | 36.22 | 0.96 | 35.13 |
| SteganoGAN | 0.84 | 36.46 | 0.83 | 36.02 |
| HCISNet | 0.92 | 38.87 | 0.91 | 37.55 |
| AVGGAN | 0.98 | 39.58 | 0.975 | 38.18 |
| **Proposed** | **0.975** | **39.02** | **0.975** | **38.75** |

**Key Findings**:
1. ✅ **Consistently highest or near-highest PSNR** (38.51-41.96 dB)
2. ✅ **SSIM > 0.96** for all cases, peaks at 0.99
3. ✅ **Outperforms SteganoGAN, HCISNet, CSIS** on both datasets
4. ✅ **Closely matches AVGGAN** while maintaining:
   - Lower model complexity
   - Real-time deployability on edge devices
   - Better structural preservation (SSIM)

---

## 10. Advantages & Contributions

### Technical Advantages

**1. Architectural Innovation**:
- ✅ Hybrid integration of SE blocks + Inception + Residual connections
- ✅ Dilated convolutions for expanded receptive field without parameter increase
- ✅ Multi-scale feature extraction at multiple resolutions

**2. Performance Excellence**:
- ✅ PSNR >39 dB (excellent reconstruction fidelity)
- ✅ SSIM ~0.98 (near-perfect structural similarity)
- ✅ Robust against compression, noise, geometric transformations

**3. Edge Deployment**:
- ✅ Real-time processing: 25-35 ms per image
- ✅ Low power consumption: 7.5-15 W
- ✅ Lightweight model: 25-30 MB
- ✅ Plug-and-play deployment on Jetson TX2

**4. Medical Imaging Suitability**:
- ✅ Preserves diagnostic integrity (low LMSE, high SC)
- ✅ Works across modalities (MRI, OCT, CT)
- ✅ High payload capacity without visual artifacts
- ✅ Suitable for telemedicine and teleradiology

---

### Scientific Contributions

1. **Novel Architecture Design**:
   - First to combine SE blocks, Inception modules, and residual connections for medical image steganography
   - Demonstrates synergistic benefits of channel attention + multi-scale features + deep learning

2. **Edge Computing Validation**:
   - First comprehensive evaluation on Jetson TX2 for medical steganography
   - Proves feasibility for low-resource clinical environments

3. **Comprehensive Robustness Testing**:
   - Extensive evaluation under four perturbation types
   - Quantifies performance degradation under realistic conditions

4. **Ablation Study**:
   - Systematic analysis of each component's contribution
   - Provides insights for future architecture design

5. **Benchmarking**:
   - Outperforms or matches 5+ state-of-the-art methods
   - Establishes new performance baseline for medical image steganography

---

## 11. Limitations & Future Work

### Current Limitations

⚠️ **Performance Under Impulsive Noise**:
- Salt & pepper noise causes most degradation (PSNR 34.70 dB, SSIM 0.931)
- Future work: Noise-aware training schemes

⚠️ **Spatial Transformations**:
- Cropping + resizing shows moderate degradation (PSNR 36.10 dB)
- Future work: Geometric transformation-invariant architectures

⚠️ **Limited Cross-Modality Testing**:
- Tested only on MRI and OCT
- Future work: Extend to CT, ultrasound, X-ray

⚠️ **Model Interpretability**:
- Deep learning models lack interpretability
- Future work: Attention visualization and feature attribution

---

### Future Research Directions

1. **Transformer-Based Attention**:
   - Integrate self-attention mechanisms
   - Potentially improve long-range dependency modeling

2. **Cross-Modality Steganography**:
   - Adapt across diverse medical imaging standards (MRI, CT, ultrasound, X-ray)
   - Domain adaptation techniques

3. **Adversarial Robustness**:
   - Test against adversarial attacks
   - Develop defense mechanisms

4. **Compression-Aware Training**:
   - Train with various JPEG quality factors
   - Improve robustness to lossy compression

5. **3D Medical Image Steganography**:
   - Extend to volumetric data (3D MRI, CT scans)
   - Utilize 3D convolutional architectures

6. **Clinical Validation**:
   - Real-world deployment studies
   - Radiologist evaluation of stego image quality

7. **Standardization**:
   - Develop interoperability standards
   - Integration with DICOM and HL7 protocols

---

## 12. Conclusion

This research introduces a **novel deep learning-based steganographic framework** specifically designed for secure medical image transmission in telemedicine and teleradiology. By using:
- **Squeeze-and-Excitation (SE) blocks** for channel-wise attention
- **Inception modules** for multi-scale feature extraction
- **Residual connections** for deep feature propagation

The proposed model effectively **balances embedding capacity, imperceptibility, and reconstruction accuracy**.

### Key Achievements

**Performance Metrics**:
- ✅ Average PSNR > 39 dB
- ✅ SSIM approaching 0.98
- ✅ High visual fidelity of stego images
- ✅ Successful reconstruction of secret images

**Robustness**:
- ✅ Robust against various perturbations (JPEG compression, Gaussian noise)
- ✅ Maintains diagnostic integrity

**Practical Deployment**:
- ✅ Optimized for real-time edge deployment on NVIDIA Jetson TX2
- ✅ Addresses practical constraints of clinical environments
- ✅ Low power consumption (7.5-15 W)
- ✅ Fast processing (25-35 ms per image)

**Innovation**:
- ✅ Dilated convolutions and multi-scale feature extraction enhance spatial context
- ✅ Suitable for high-resolution medical imagery
- ✅ Unlike traditional techniques, provides both security and real-time capability

### Impact

This work establishes a **viable pathway for implementing secure, lightweight, and scalable steganographic solutions** in resource-constrained settings where both **data confidentiality and real-time processing are critical**.

The integration of advanced deep learning techniques with edge computing proves that high-security medical image steganography is achievable in practical clinical environments, paving the way for widespread adoption in telemedicine, remote diagnostics, and electronic health record systems.

---

## Data Availability

**Datasets used** (all publicly available on Kaggle):

1. **Cover Images**:
   - https://www.kaggle.com/datasets/imsparsh/flowers-dataset
   - https://www.kaggle.com/datasets/muhammedtausif/rose-flowers

2. **Secret Images (Medical)**:
   - MRI Brain (tumor detection): https://www.kaggle.com/navoneel/brain-mri-images-for-brain-tumor-detection
   - OCT Eye Scans (glaucoma detection): https://www.kaggle.com/datasets/sshikamaru/glaucoma-detection

---

## References Summary

**35 References** covering:
- Classical steganography (LSB, PVD) - 10 refs
- Transform domain methods (DCT, DWT, DFT) - 4 refs
- Deep learning steganography - 8 refs
- Medical imaging datasets - 4 refs
- SE blocks and attention mechanisms - 3 refs
- Benchmarking methods (HiDDeN, SteganoGAN, HCISNet, AVGGAN) - 4 refs
- Additional ML and medical imaging refs - 2 refs

---

## Keywords

Medical image security, Steganography, Squeeze-and-Excitation, Inception module, Deep learning, Jetson TX2, Telemedicine, Encoder-decoder architecture, Residual connections, Dilated convolutions, Edge computing, Real-time processing, PSNR, SSIM, Robustness analysis

